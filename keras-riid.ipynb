{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/riiid-test-answer-prediction/example_test.csv\n/kaggle/input/riiid-test-answer-prediction/train.csv\n/kaggle/input/riiid-test-answer-prediction/lectures.csv\n/kaggle/input/riiid-test-answer-prediction/questions.csv\n/kaggle/input/riiid-test-answer-prediction/example_sample_submission.csv\n/kaggle/input/riiid-test-answer-prediction/riiideducation/competition.cpython-37m-x86_64-linux-gnu.so\n/kaggle/input/riiid-test-answer-prediction/riiideducation/__init__.py\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport lightgbm as lgb\nfrom sklearn.metrics import roc_auc_score\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nimport gc\nimport riiideducation\nenv = riiideducation.make_env()\n\n","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dir_path = '/kaggle/input/riiid-test-answer-prediction/'\nfile_train = 'train.csv'\nfile_questions = 'questions.csv'\n\n# nrows =  100 * 10000\nnrows = None\n\n# 压缩内存\nmax_num = 126\n\ntrain = pd.read_csv(\n                    dir_path + file_train, \n                    nrows=nrows, \n                    usecols=['row_id', 'timestamp', 'user_id', 'content_id', \n                             'content_type_id', 'task_container_id', 'answered_correctly',\n                            'prior_question_elapsed_time','prior_question_had_explanation'],\n                    dtype={\n                            'row_id': 'int64',\n                            'timestamp': 'int64',\n                            'user_id': 'int32',\n                            'content_id': 'int16',\n                            'content_type_id': 'int8',\n                            'task_container_id': 'int8',\n#                           'user_answer': 'int8',\n                            'answered_correctly': 'int8',\n                            'prior_question_elapsed_time': 'float32',\n                            'prior_question_had_explanation': 'str'\n                        }\n                   )\n\nquestions = pd.read_csv(\n                        dir_path + file_questions, \n                        nrows=nrows,\n                        usecols=['question_id','bundle_id','part'], \n                        dtype={\n                           'question_id': 'int16',\n                           'bundle_id': 'int16',\n#                           'correct_answer':'int8',\n                           'part': 'int8',\n#                            'tags': 'str',#序列的加入没有带来太大提升\n                       }\n                    )\n\n\ntrain['prior_question_had_explanation'] = train['prior_question_had_explanation'].map({'True':1,'False':0}).fillna(-1).astype(np.int8)\n\ntrain = train[train['content_type_id']==0]\n\ngc.collect()\n\ntrain = train.groupby(['user_id']).tail(max_num)\n\ntrain = pd.merge(\n        left=train,\n        right=questions,\n        how='left',\n        left_on='content_id',\n        right_on='question_id'\n        )\n\ntrain = train.fillna(0)\ndel train[\"question_id\"]\nprint(gc.collect())","execution_count":3,"outputs":[{"output_type":"stream","text":"0\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# 计算user和题目的题目答对与否的特征(在测试集中需要实时更新)"},{"metadata":{"trusted":true},"cell_type":"code","source":"user_agg = train.groupby('user_id')[\"answered_correctly\"].agg(['sum', 'count'])\ncontent_agg = train.groupby('content_id')[\"answered_correctly\"].agg(['sum', 'count'])","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 计算题目的难度和已回答该题目的数量"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['content_count'] = train['content_id'].map(content_agg['count']).astype('int32')\ntrain[\"content_count\"]=train[\"content_count\"].fillna(1)\ntrain['question_difficulty'] = train['content_id'].map(content_agg['sum'] / content_agg['count'])","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 计算用户实时的答题正确率"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['lag'] = train.groupby('user_id')['answered_correctly'].shift()#标签沿着列的方向下移一位\ncum = train.groupby('user_id')['lag'].agg(['cumsum', 'cumcount'])\ntrain['user_correctness'] = cum['cumsum'] / cum['cumcount']#计算实时准确率\ntrain.drop(columns=['lag'], inplace=True)\ntrain[\"user_correctness\"]=train[\"user_correctness\"].fillna(0.7)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.tail()","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"             row_id  timestamp     user_id  content_id  content_type_id  \\\n25105220  101230327  428564420  2147482888        3586                0   \n25105221  101230328  428585000  2147482888        6341                0   \n25105222  101230329  428613475  2147482888        4212                0   \n25105223  101230330  428649406  2147482888        6343                0   \n25105224  101230331  428692118  2147482888        7995                0   \n\n          task_container_id  answered_correctly  prior_question_elapsed_time  \\\n25105220                 22                   1                      18000.0   \n25105221                 23                   1                      14000.0   \n25105222                 24                   1                      14000.0   \n25105223                 25                   0                      22000.0   \n25105224                 26                   1                      29000.0   \n\n          prior_question_had_explanation  bundle_id  part  content_count  \\\n25105220                               1       3586     5            981   \n25105221                               1       6341     5           2148   \n25105222                               1       4212     5           8422   \n25105223                               1       6343     5           1196   \n25105224                               1       7995     5           1578   \n\n          question_difficulty  user_correctness  \n25105220             0.745158          0.500000  \n25105221             0.514898          0.521739  \n25105222             0.595702          0.541667  \n25105223             0.627926          0.560000  \n25105224             0.636882          0.538462  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_id</th>\n      <th>timestamp</th>\n      <th>user_id</th>\n      <th>content_id</th>\n      <th>content_type_id</th>\n      <th>task_container_id</th>\n      <th>answered_correctly</th>\n      <th>prior_question_elapsed_time</th>\n      <th>prior_question_had_explanation</th>\n      <th>bundle_id</th>\n      <th>part</th>\n      <th>content_count</th>\n      <th>question_difficulty</th>\n      <th>user_correctness</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>25105220</th>\n      <td>101230327</td>\n      <td>428564420</td>\n      <td>2147482888</td>\n      <td>3586</td>\n      <td>0</td>\n      <td>22</td>\n      <td>1</td>\n      <td>18000.0</td>\n      <td>1</td>\n      <td>3586</td>\n      <td>5</td>\n      <td>981</td>\n      <td>0.745158</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <th>25105221</th>\n      <td>101230328</td>\n      <td>428585000</td>\n      <td>2147482888</td>\n      <td>6341</td>\n      <td>0</td>\n      <td>23</td>\n      <td>1</td>\n      <td>14000.0</td>\n      <td>1</td>\n      <td>6341</td>\n      <td>5</td>\n      <td>2148</td>\n      <td>0.514898</td>\n      <td>0.521739</td>\n    </tr>\n    <tr>\n      <th>25105222</th>\n      <td>101230329</td>\n      <td>428613475</td>\n      <td>2147482888</td>\n      <td>4212</td>\n      <td>0</td>\n      <td>24</td>\n      <td>1</td>\n      <td>14000.0</td>\n      <td>1</td>\n      <td>4212</td>\n      <td>5</td>\n      <td>8422</td>\n      <td>0.595702</td>\n      <td>0.541667</td>\n    </tr>\n    <tr>\n      <th>25105223</th>\n      <td>101230330</td>\n      <td>428649406</td>\n      <td>2147482888</td>\n      <td>6343</td>\n      <td>0</td>\n      <td>25</td>\n      <td>0</td>\n      <td>22000.0</td>\n      <td>1</td>\n      <td>6343</td>\n      <td>5</td>\n      <td>1196</td>\n      <td>0.627926</td>\n      <td>0.560000</td>\n    </tr>\n    <tr>\n      <th>25105224</th>\n      <td>101230331</td>\n      <td>428692118</td>\n      <td>2147482888</td>\n      <td>7995</td>\n      <td>0</td>\n      <td>26</td>\n      <td>1</td>\n      <td>29000.0</td>\n      <td>1</td>\n      <td>7995</td>\n      <td>5</td>\n      <td>1578</td>\n      <td>0.636882</td>\n      <td>0.538462</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#处理类别特征\nclass cat_deal:\n    def __init__(self):\n        self.max_len = 0\n        self.dict_map = {}\n    \n    def fit(self, cat_list):\n        index = 1 \n        for cat_i in cat_list:\n            if cat_i not in self.dict_map:\n                self.dict_map[cat_i] = index\n                index += 1\n        self.max_len = index + 1\n        \n    def transform(self, cat_list):\n        cat_transform_list = []\n        for cat_i in cat_list:\n            if cat_i in self.dict_map:\n                cat_transform_list.append(self.dict_map[cat_i])\n            else:\n                cat_transform_list.append(0)\n        return cat_transform_list\n#处理浮点特征\nclass float_deal:\n    def __init__(self):\n        self.max = 0\n        self.min = 0\n        self.max_min = 0 \n        \n    def fit(self, float_list):\n        for float_i in float_list:\n            if float_i < self.min:\n                self.min = float_i\n            if float_i > self.max:\n                self.max = float_i\n        self.max_min = self.max - self.min\n        \n    def transform(self, float_list):\n        float_transform_list = []\n        for float_i in float_list:\n            if float_i < self.min:\n                float_transform_list.append(0)\n            elif float_i > self.max:\n                float_transform_list.append(1)\n            else:\n                float_transform_list.append(float_i/self.max_min)\n        return float_transform_list\n    \n#处理序列特征\nclass cat_seq_deal:\n    def __init__(self,sep_len=6,sep=' '):\n        self.sep_len=sep_len\n        self.sep=sep\n        self.max_len=0\n        self.dict_map={}\n        \n    def fit(self,cat_seq_list):\n        index=1\n        for cat_seq_i in cat_seq_list:\n            cat_seq_i =cat_seq_i.split(self.sep)\n            for cat_i in cat_seq_i:\n                if cat_i not in self.dict_map:\n                    self.dict_map[cat_i]=index\n                    index+=1\n        self.max_len=index+1\n    \n    def transform(self,cat_seq_list):\n        cat_transform_list=[]\n        for cat_seq_i in cat_seq_list:\n            cat_seq_i =cat_seq_i.split(self.sep)\n            len_cat_seq_i=len(cat_seq_i)\n            if len_cat_seq_i>=self.sep_len:\n                cat_seq_i=cat_seq_i[:self.sep_len]\n            else:\n                cat_seq_i=cat_seq_i+[0]*(self.sep_len-len_cat_seq_i)\n            cat_seq_n=[]\n            for cat_i in cat_seq_i:\n                if cat_i in self.dict_map:\n                    cat_seq_n.append(self.dict_map[cat_i])\n                else:\n                    cat_seq_n.append(0)\n            cat_transform_list.append(cat_seq_n)\n        return cat_transform_list  \n","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dict_cat_class = {}\nfor columns in ['user_id','content_id',\\\n                'task_container_id','prior_question_had_explanation',\\\n                'bundle_id','part']:\n    dict_cat_class[columns] = cat_deal()\n    dict_cat_class[columns].fit(train[columns])\n\n    train[columns] = dict_cat_class[columns].transform(train[columns])\n    print(columns)\n\n\ndict_float_class = {}\nfor columns in ['timestamp','prior_question_elapsed_time','content_count',\\\n                'question_difficulty','user_correctness']:\n    dict_float_class[columns] = float_deal()\n    dict_float_class[columns].fit(train[columns])\n    \n    train[columns] = dict_float_class[columns].transform(train[columns])\n    print(columns)\n    \n# dict_cat_seq_class={}\n# for columns in ['tags']:\n#     dict_cat_seq_class[columns]=cat_seq_deal(sep_len=6,sep=' ')\n#     dict_cat_seq_class[columns].fit(train[columns])\n    \n#     train[columns]=dict_cat_seq_class[columns].transform(train[columns])\n#     print('tags')\n\n                    ","execution_count":9,"outputs":[{"output_type":"stream","text":"user_id\ncontent_id\ntask_container_id\nprior_question_had_explanation\nbundle_id\npart\ntimestamp\nprior_question_elapsed_time\ncontent_count\nquestion_difficulty\nuser_correctness\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.tail()","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"             row_id  timestamp  user_id  content_id  content_type_id  \\\n25105220  101230327   0.004902   393656        6749                0   \n25105221  101230328   0.004902   393656        5999                0   \n25105222  101230329   0.004903   393656         974                0   \n25105223  101230330   0.004903   393656       11068                0   \n25105224  101230331   0.004903   393656        8139                0   \n\n          task_container_id  answered_correctly  prior_question_elapsed_time  \\\n25105220                 23                   1                     0.060000   \n25105221                 24                   1                     0.046667   \n25105222                 25                   1                     0.046667   \n25105223                 26                   0                     0.073333   \n25105224                 27                   1                     0.096667   \n\n          prior_question_had_explanation  bundle_id  part  content_count  \\\n25105220                               3       5480     1       0.007075   \n25105221                               3       4896     1       0.015491   \n25105222                               3        806     1       0.060737   \n25105223                               3       8341     1       0.008625   \n25105224                               3       6432     1       0.011380   \n\n          question_difficulty  user_correctness  \n25105220             0.745158          0.500000  \n25105221             0.514898          0.521739  \n25105222             0.595702          0.541667  \n25105223             0.627926          0.560000  \n25105224             0.636882          0.538462  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_id</th>\n      <th>timestamp</th>\n      <th>user_id</th>\n      <th>content_id</th>\n      <th>content_type_id</th>\n      <th>task_container_id</th>\n      <th>answered_correctly</th>\n      <th>prior_question_elapsed_time</th>\n      <th>prior_question_had_explanation</th>\n      <th>bundle_id</th>\n      <th>part</th>\n      <th>content_count</th>\n      <th>question_difficulty</th>\n      <th>user_correctness</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>25105220</th>\n      <td>101230327</td>\n      <td>0.004902</td>\n      <td>393656</td>\n      <td>6749</td>\n      <td>0</td>\n      <td>23</td>\n      <td>1</td>\n      <td>0.060000</td>\n      <td>3</td>\n      <td>5480</td>\n      <td>1</td>\n      <td>0.007075</td>\n      <td>0.745158</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <th>25105221</th>\n      <td>101230328</td>\n      <td>0.004902</td>\n      <td>393656</td>\n      <td>5999</td>\n      <td>0</td>\n      <td>24</td>\n      <td>1</td>\n      <td>0.046667</td>\n      <td>3</td>\n      <td>4896</td>\n      <td>1</td>\n      <td>0.015491</td>\n      <td>0.514898</td>\n      <td>0.521739</td>\n    </tr>\n    <tr>\n      <th>25105222</th>\n      <td>101230329</td>\n      <td>0.004903</td>\n      <td>393656</td>\n      <td>974</td>\n      <td>0</td>\n      <td>25</td>\n      <td>1</td>\n      <td>0.046667</td>\n      <td>3</td>\n      <td>806</td>\n      <td>1</td>\n      <td>0.060737</td>\n      <td>0.595702</td>\n      <td>0.541667</td>\n    </tr>\n    <tr>\n      <th>25105223</th>\n      <td>101230330</td>\n      <td>0.004903</td>\n      <td>393656</td>\n      <td>11068</td>\n      <td>0</td>\n      <td>26</td>\n      <td>0</td>\n      <td>0.073333</td>\n      <td>3</td>\n      <td>8341</td>\n      <td>1</td>\n      <td>0.008625</td>\n      <td>0.627926</td>\n      <td>0.560000</td>\n    </tr>\n    <tr>\n      <th>25105224</th>\n      <td>101230331</td>\n      <td>0.004903</td>\n      <td>393656</td>\n      <td>8139</td>\n      <td>0</td>\n      <td>27</td>\n      <td>1</td>\n      <td>0.096667</td>\n      <td>3</td>\n      <td>6432</td>\n      <td>1</td>\n      <td>0.011380</td>\n      <td>0.636882</td>\n      <td>0.538462</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def squeeze(embedding):\n    embedding = tf.squeeze(embedding,axis=1)\n    return embedding\ndef concat(embedding_list):\n    embedding = tf.concat(embedding_list, axis=1)\n    return embedding\ndef multiply(multi_x_y):\n    multi_x = multi_x_y[0]\n    multi_y = multi_x_y[1]\n    multi_x_y = tf.multiply(multi_x, multi_y)\n    return multi_x_y\ndef add(add_x_y):\n    multi_x=multi_x_y[0]\n    multi_y=multi_x_y[1]\n    multi_x_y=tf.add(multi_x,multi_x)\n    return multi_x_y\n#浮点数据分桶函数，处理后可当做类别特征使用\ndef cast(input_float,bin=200):\n    float_2_cat=tf.cast(input_float/1.02*bin,dtype=tf.int64)\n    return float_2_cat","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#deepnFFm\n# 浮点数据输入\ninput_timestamp = tf.keras.Input(shape=(1,))\ninput_prior_question_elapsed_time = tf.keras.Input(shape=(1,))\ninput_content_count = tf.keras.Input(shape=(1,))\ninput_question_difficulty = tf.keras.Input(shape=(1,))\ninput_user_correctness = tf.keras.Input(shape=(1,))\n\n# 类别数据输入\ninput_user = tf.keras.Input(shape=(1,))\n#可对用户进行类似item dropout的操作\n\n\ninput_content = tf.keras.Input(shape=(1,))\ninput_task_container = tf.keras.Input(shape=(1,))\ninput_prior_question_had_explanation = tf.keras.Input(shape=(1,))\ninput_bundle = tf.keras.Input(shape=(1,))\ninput_part = tf.keras.Input(shape=(1,))\n\n#序列特征\n# input_tags=tf.keras.Input(shape=(6,))\n# embedding_tags_seq=tf.keras.layers.Embedding(dict_cat_seq_class['tags'].max_len,\n#                                            64,input_length=1)(input_tags)\n# embedding_tags_seq=tf.reduce_mean(embedding_tags_seq,axis=1)\n# embedding_tags_seq=tf.keras.layers.Dense(64,activation=tf.nn.relu)(embedding_tags_seq)\n\n# 所有输入\ninputs = [input_question_difficulty,input_user_correctness,input_content_count,\\\n         input_timestamp,input_prior_question_elapsed_time,\\\n         input_user,input_content,\\\n         input_task_container,input_prior_question_had_explanation,\\\n         input_bundle,input_part\n#           ,input_tags\n         ]\n\n# Wide部分\n# 类别特征embeeding转换 \nembedding_user_wide = tf.keras.layers.Embedding(dict_cat_class['user_id'].max_len,\n                                           1, input_length=1)(input_user)\nembedding_user_wide = tf.keras.layers.Lambda(squeeze)(embedding_user_wide)\n\nembedding_content_wide = tf.keras.layers.Embedding(dict_cat_class['content_id'].max_len,\n                                              1, input_length=1)(input_content)\nembedding_content_wide = tf.keras.layers.Lambda(squeeze)(embedding_content_wide)\n\nembedding_task_container_wide = tf.keras.layers.Embedding(dict_cat_class['task_container_id'].max_len,\n                                                     1, input_length=1)(input_task_container)\nembedding_task_container_wide = tf.keras.layers.Lambda(squeeze)(embedding_task_container_wide)\n\nembedding_prior_question_had_explanation_wide = tf.keras.layers.Embedding(dict_cat_class['prior_question_had_explanation'].max_len, \n                                                                     1, input_length=1)(input_prior_question_had_explanation)\nembedding_prior_question_had_explanation_wide = tf.keras.layers.Lambda(squeeze)(embedding_prior_question_had_explanation_wide)\n\nembedding_bundle_wide = tf.keras.layers.Embedding(dict_cat_class['bundle_id'].max_len,\n                                             1, input_length=1)(input_bundle)\nembedding_bundle_wide = tf.keras.layers.Lambda(squeeze)(embedding_bundle_wide)\n\nembedding_part_wide = tf.keras.layers.Embedding(dict_cat_class['part'].max_len,\n                                           1, input_length=1)(input_part)\nembedding_part_wide = tf.keras.layers.Lambda(squeeze)(embedding_part_wide)\n\n# 连续值分桶,变成类别特征\ninput_timestamp_cat = tf.keras.layers.Lambda(cast)(input_timestamp)\ninput_prior_question_elapsed_time_cat = tf.keras.layers.Lambda(cast)(input_prior_question_elapsed_time)\n\n\nembedding_timestamp_cat_wide = tf.keras.layers.Embedding(200,\n                                           1, input_length=1)(input_timestamp_cat)\nembedding_timestamp_cat_wide = tf.keras.layers.Lambda(squeeze)(embedding_timestamp_cat_wide)\n\nembedding_prior_question_elapsed_time_cat_wide = tf.keras.layers.Embedding(200,\n                                              1, input_length=1)(input_prior_question_elapsed_time_cat)\nembedding_prior_question_elapsed_time_cat_wide = tf.keras.layers.Lambda(squeeze)(embedding_prior_question_elapsed_time_cat_wide)\n# 合并类别特征对应的embeeding特征和浮点特征\nembedding_all = [input_question_difficulty,input_user_correctness,input_content_count,\\\n                embedding_timestamp_cat_wide,embedding_prior_question_elapsed_time_cat_wide,\\\n                embedding_user_wide, embedding_content_wide, embedding_task_container_wide,\\\n                embedding_prior_question_had_explanation_wide, embedding_bundle_wide, embedding_part_wide]\n\nwide_all = embedding_all\n# wide layer（线性回归）\nwide_layer = tf.keras.layers.Lambda(concat)(wide_all) \nwide_layer = tf.keras.layers.Dense(32,activation=tf.nn.relu)(wide_layer)\n\n\n\n# FM和Deep部分\n#连续特征\n# embedding float\n# embedding_timestamp_deep = tf.keras.layers.Dense(64, activation=tf.nn.relu)(input_timestamp)\n# embedding_prior_question_elapsed_time_deep = tf.keras.layers.Dense(64, activation=tf.nn.relu)(input_prior_question_elapsed_time)\nembedding_question_difficulty_deep = tf.keras.layers.Dense(64, activation=tf.nn.relu)(input_question_difficulty)\nembedding_user_correctness_deep = tf.keras.layers.Dense(64, activation=tf.nn.relu)(input_user_correctness)\nembedding_content_count_deep = tf.keras.layers.Dense(64, activation=tf.nn.relu)(input_content_count)\n\n#分桶后的类别数据\nembedding_timestamp_deep = tf.keras.layers.Embedding(200,\n                                           64, input_length=1)(input_timestamp_cat)\nembedding_timestamp_deep = tf.keras.layers.Lambda(squeeze)(embedding_timestamp_deep)\n\nembedding_prior_question_elapsed_time_deep = tf.keras.layers.Embedding(200,\n                                           64, input_length=1)(input_prior_question_elapsed_time_cat)\nembedding_prior_question_elapsed_time_deep = tf.keras.layers.Lambda(squeeze)(embedding_prior_question_elapsed_time_deep)\n\n# 类别特征embeeding转换 \nembedding_user_deep = tf.keras.layers.Embedding(dict_cat_class['user_id'].max_len,\n                                           64, input_length=1)(input_user)\nembedding_user_deep = tf.keras.layers.Lambda(squeeze)(embedding_user_deep)\n\nembedding_content_deep = tf.keras.layers.Embedding(dict_cat_class['content_id'].max_len,\n                                              64, input_length=1)(input_content)\nembedding_content_deep = tf.keras.layers.Lambda(squeeze)(embedding_content_deep)\n\nembedding_task_container_deep = tf.keras.layers.Embedding(dict_cat_class['task_container_id'].max_len,\n                                                     64, input_length=1)(input_task_container)\nembedding_task_container_deep = tf.keras.layers.Lambda(squeeze)(embedding_task_container_deep)\n\nembedding_prior_question_had_explanation_deep = tf.keras.layers.Embedding(dict_cat_class['prior_question_had_explanation'].max_len, \n                                                                     64, input_length=1)(input_prior_question_had_explanation)\nembedding_prior_question_had_explanation_deep = tf.keras.layers.Lambda(squeeze)(embedding_prior_question_had_explanation_deep)\n\nembedding_bundle_deep = tf.keras.layers.Embedding(dict_cat_class['bundle_id'].max_len,\n                                             64, input_length=1)(input_bundle)\nembedding_bundle_deep = tf.keras.layers.Lambda(squeeze)(embedding_bundle_deep)\n\nembedding_part_deep = tf.keras.layers.Embedding(dict_cat_class['part'].max_len,\n                                           64, input_length=1)(input_part)\nembedding_part_deep = tf.keras.layers.Lambda(squeeze)(embedding_part_deep)\n\n# 合并类别特征对应的embeeding特征和浮点特征\nembedding_all = [embedding_question_difficulty_deep,embedding_user_correctness_deep,embedding_content_count_deep,embedding_timestamp_deep,embedding_prior_question_elapsed_time_deep,\\\n                embedding_user_deep, embedding_content_deep, embedding_task_container_deep,\\\n                embedding_prior_question_had_explanation_deep, embedding_bundle_deep, embedding_part_deep]\n\n\n\n# FM部分(embedding+特征交叉对应元素相乘)\nfm_all = embedding_all \nfm1, fm2 = [], []\nfor i, embedding_i in enumerate(embedding_all):\n    for j, embedding_j in enumerate(embedding_all):\n        if i > j:\n            fm1.append(embedding_i), fm2.append(embedding_j)\nfm1_layer = tf.keras.layers.Lambda(concat)(fm1)\nfm2_layer = tf.keras.layers.Lambda(concat)(fm2)     \n\nfm_layer = tf.keras.layers.Lambda(multiply)([fm1_layer,fm2_layer])\nfm_layer=tf.nn.dropout(fm_layer,0.9)\nfm_layer=tf.keras.layers.Dense(64, activation=tf.nn.relu)(fm_layer)\n\n# Deep部分(embedding+DNN)\ndeep_all = embedding_all \ndeep_layer = tf.keras.layers.Lambda(concat)(deep_all) \n#FC \nfor unit_i in [16,32,16]:#[16,32,16]\n    deep_layer = tf.keras.layers.Dense(unit_i, activation=tf.nn.relu)(deep_layer)\n    #防止过拟合\n\n    \n# logit输出\ndeep_wide_fm_layer = tf.keras.layers.Lambda(concat)([deep_layer,wide_layer,fm_layer]) \n# deep_wide_fm_layer=tf.keras.layers.Dense(32, activation=tf.nn.relu)(deep_wide_fm_layer)\nlogit = tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)(deep_wide_fm_layer)\n#效果不好\n# logit = tf.expand_dims(tf.nn.sigmoid(tf.reduce_sum(deep_wide_fm_layer,axis=1)),axis=1)\n\n# 模型输入和输出\nmodel = tf.keras.models.Model(inputs=inputs, outputs=logit)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":13,"outputs":[{"output_type":"stream","text":"Model: \"functional_1\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, 1)]          0                                            \n__________________________________________________________________________________________________\ninput_2 (InputLayer)            [(None, 1)]          0                                            \n__________________________________________________________________________________________________\nlambda_6 (Lambda)               (None, 1)            0           input_1[0][0]                    \n__________________________________________________________________________________________________\nlambda_7 (Lambda)               (None, 1)            0           input_2[0][0]                    \n__________________________________________________________________________________________________\ninput_6 (InputLayer)            [(None, 1)]          0                                            \n__________________________________________________________________________________________________\ninput_7 (InputLayer)            [(None, 1)]          0                                            \n__________________________________________________________________________________________________\ninput_8 (InputLayer)            [(None, 1)]          0                                            \n__________________________________________________________________________________________________\ninput_9 (InputLayer)            [(None, 1)]          0                                            \n__________________________________________________________________________________________________\ninput_10 (InputLayer)           [(None, 1)]          0                                            \n__________________________________________________________________________________________________\ninput_11 (InputLayer)           [(None, 1)]          0                                            \n__________________________________________________________________________________________________\ninput_4 (InputLayer)            [(None, 1)]          0                                            \n__________________________________________________________________________________________________\ninput_5 (InputLayer)            [(None, 1)]          0                                            \n__________________________________________________________________________________________________\ninput_3 (InputLayer)            [(None, 1)]          0                                            \n__________________________________________________________________________________________________\nembedding_8 (Embedding)         (None, 1, 64)        12800       lambda_6[0][0]                   \n__________________________________________________________________________________________________\nembedding_9 (Embedding)         (None, 1, 64)        12800       lambda_7[0][0]                   \n__________________________________________________________________________________________________\nembedding_10 (Embedding)        (None, 1, 64)        25194112    input_6[0][0]                    \n__________________________________________________________________________________________________\nembedding_11 (Embedding)        (None, 1, 64)        865152      input_7[0][0]                    \n__________________________________________________________________________________________________\nembedding_12 (Embedding)        (None, 1, 64)        16512       input_8[0][0]                    \n__________________________________________________________________________________________________\nembedding_13 (Embedding)        (None, 1, 64)        320         input_9[0][0]                    \n__________________________________________________________________________________________________\nembedding_14 (Embedding)        (None, 1, 64)        624768      input_10[0][0]                   \n__________________________________________________________________________________________________\nembedding_15 (Embedding)        (None, 1, 64)        576         input_11[0][0]                   \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 64)           128         input_4[0][0]                    \n__________________________________________________________________________________________________\ndense_2 (Dense)                 (None, 64)           128         input_5[0][0]                    \n__________________________________________________________________________________________________\ndense_3 (Dense)                 (None, 64)           128         input_3[0][0]                    \n__________________________________________________________________________________________________\nlambda_11 (Lambda)              (None, 64)           0           embedding_8[0][0]                \n__________________________________________________________________________________________________\nlambda_12 (Lambda)              (None, 64)           0           embedding_9[0][0]                \n__________________________________________________________________________________________________\nlambda_13 (Lambda)              (None, 64)           0           embedding_10[0][0]               \n__________________________________________________________________________________________________\nlambda_14 (Lambda)              (None, 64)           0           embedding_11[0][0]               \n__________________________________________________________________________________________________\nlambda_15 (Lambda)              (None, 64)           0           embedding_12[0][0]               \n__________________________________________________________________________________________________\nlambda_16 (Lambda)              (None, 64)           0           embedding_13[0][0]               \n__________________________________________________________________________________________________\nlambda_17 (Lambda)              (None, 64)           0           embedding_14[0][0]               \n__________________________________________________________________________________________________\nlambda_18 (Lambda)              (None, 64)           0           embedding_15[0][0]               \n__________________________________________________________________________________________________\nlambda_19 (Lambda)              (None, 3520)         0           dense_2[0][0]                    \n                                                                 dense_3[0][0]                    \n                                                                 dense_3[0][0]                    \n                                                                 lambda_11[0][0]                  \n                                                                 lambda_11[0][0]                  \n                                                                 lambda_11[0][0]                  \n                                                                 lambda_12[0][0]                  \n                                                                 lambda_12[0][0]                  \n                                                                 lambda_12[0][0]                  \n                                                                 lambda_12[0][0]                  \n                                                                 lambda_13[0][0]                  \n                                                                 lambda_13[0][0]                  \n                                                                 lambda_13[0][0]                  \n                                                                 lambda_13[0][0]                  \n                                                                 lambda_13[0][0]                  \n                                                                 lambda_14[0][0]                  \n                                                                 lambda_14[0][0]                  \n                                                                 lambda_14[0][0]                  \n                                                                 lambda_14[0][0]                  \n                                                                 lambda_14[0][0]                  \n                                                                 lambda_14[0][0]                  \n                                                                 lambda_15[0][0]                  \n                                                                 lambda_15[0][0]                  \n                                                                 lambda_15[0][0]                  \n                                                                 lambda_15[0][0]                  \n                                                                 lambda_15[0][0]                  \n                                                                 lambda_15[0][0]                  \n                                                                 lambda_15[0][0]                  \n                                                                 lambda_16[0][0]                  \n                                                                 lambda_16[0][0]                  \n                                                                 lambda_16[0][0]                  \n                                                                 lambda_16[0][0]                  \n                                                                 lambda_16[0][0]                  \n                                                                 lambda_16[0][0]                  \n                                                                 lambda_16[0][0]                  \n                                                                 lambda_16[0][0]                  \n                                                                 lambda_17[0][0]                  \n                                                                 lambda_17[0][0]                  \n                                                                 lambda_17[0][0]                  \n                                                                 lambda_17[0][0]                  \n                                                                 lambda_17[0][0]                  \n                                                                 lambda_17[0][0]                  \n                                                                 lambda_17[0][0]                  \n                                                                 lambda_17[0][0]                  \n                                                                 lambda_17[0][0]                  \n                                                                 lambda_18[0][0]                  \n                                                                 lambda_18[0][0]                  \n                                                                 lambda_18[0][0]                  \n                                                                 lambda_18[0][0]                  \n                                                                 lambda_18[0][0]                  \n                                                                 lambda_18[0][0]                  \n                                                                 lambda_18[0][0]                  \n                                                                 lambda_18[0][0]                  \n                                                                 lambda_18[0][0]                  \n                                                                 lambda_18[0][0]                  \n__________________________________________________________________________________________________\nlambda_20 (Lambda)              (None, 3520)         0           dense_1[0][0]                    \n                                                                 dense_1[0][0]                    \n                                                                 dense_2[0][0]                    \n                                                                 dense_1[0][0]                    \n                                                                 dense_2[0][0]                    \n                                                                 dense_3[0][0]                    \n                                                                 dense_1[0][0]                    \n                                                                 dense_2[0][0]                    \n                                                                 dense_3[0][0]                    \n                                                                 lambda_11[0][0]                  \n                                                                 dense_1[0][0]                    \n                                                                 dense_2[0][0]                    \n                                                                 dense_3[0][0]                    \n                                                                 lambda_11[0][0]                  \n                                                                 lambda_12[0][0]                  \n                                                                 dense_1[0][0]                    \n                                                                 dense_2[0][0]                    \n                                                                 dense_3[0][0]                    \n                                                                 lambda_11[0][0]                  \n                                                                 lambda_12[0][0]                  \n                                                                 lambda_13[0][0]                  \n                                                                 dense_1[0][0]                    \n                                                                 dense_2[0][0]                    \n                                                                 dense_3[0][0]                    \n                                                                 lambda_11[0][0]                  \n                                                                 lambda_12[0][0]                  \n                                                                 lambda_13[0][0]                  \n                                                                 lambda_14[0][0]                  \n                                                                 dense_1[0][0]                    \n                                                                 dense_2[0][0]                    \n                                                                 dense_3[0][0]                    \n                                                                 lambda_11[0][0]                  \n                                                                 lambda_12[0][0]                  \n                                                                 lambda_13[0][0]                  \n                                                                 lambda_14[0][0]                  \n                                                                 lambda_15[0][0]                  \n                                                                 dense_1[0][0]                    \n                                                                 dense_2[0][0]                    \n                                                                 dense_3[0][0]                    \n                                                                 lambda_11[0][0]                  \n                                                                 lambda_12[0][0]                  \n                                                                 lambda_13[0][0]                  \n                                                                 lambda_14[0][0]                  \n                                                                 lambda_15[0][0]                  \n                                                                 lambda_16[0][0]                  \n                                                                 dense_1[0][0]                    \n                                                                 dense_2[0][0]                    \n                                                                 dense_3[0][0]                    \n                                                                 lambda_11[0][0]                  \n                                                                 lambda_12[0][0]                  \n                                                                 lambda_13[0][0]                  \n                                                                 lambda_14[0][0]                  \n                                                                 lambda_15[0][0]                  \n                                                                 lambda_16[0][0]                  \n                                                                 lambda_17[0][0]                  \n__________________________________________________________________________________________________\nlambda_21 (Lambda)              (None, 3520)         0           lambda_19[0][0]                  \n                                                                 lambda_20[0][0]                  \n__________________________________________________________________________________________________\ntf_op_layer_Shape (TensorFlowOp [(2,)]               0           lambda_21[0][0]                  \n__________________________________________________________________________________________________\ntf_op_layer_RandomUniform (Tens [(None, 3520)]       0           tf_op_layer_Shape[0][0]          \n__________________________________________________________________________________________________\nlambda_22 (Lambda)              (None, 704)          0           dense_1[0][0]                    \n                                                                 dense_2[0][0]                    \n                                                                 dense_3[0][0]                    \n                                                                 lambda_11[0][0]                  \n                                                                 lambda_12[0][0]                  \n                                                                 lambda_13[0][0]                  \n                                                                 lambda_14[0][0]                  \n                                                                 lambda_15[0][0]                  \n                                                                 lambda_16[0][0]                  \n                                                                 lambda_17[0][0]                  \n                                                                 lambda_18[0][0]                  \n__________________________________________________________________________________________________\nembedding_6 (Embedding)         (None, 1, 1)         200         lambda_6[0][0]                   \n__________________________________________________________________________________________________\nembedding_7 (Embedding)         (None, 1, 1)         200         lambda_7[0][0]                   \n__________________________________________________________________________________________________\nembedding (Embedding)           (None, 1, 1)         393658      input_6[0][0]                    \n__________________________________________________________________________________________________\nembedding_1 (Embedding)         (None, 1, 1)         13518       input_7[0][0]                    \n__________________________________________________________________________________________________\nembedding_2 (Embedding)         (None, 1, 1)         258         input_8[0][0]                    \n__________________________________________________________________________________________________\nembedding_3 (Embedding)         (None, 1, 1)         5           input_9[0][0]                    \n__________________________________________________________________________________________________\nembedding_4 (Embedding)         (None, 1, 1)         9762        input_10[0][0]                   \n__________________________________________________________________________________________________\nembedding_5 (Embedding)         (None, 1, 1)         9           input_11[0][0]                   \n__________________________________________________________________________________________________\ntf_op_layer_GreaterEqual (Tenso [(None, 3520)]       0           tf_op_layer_RandomUniform[0][0]  \n__________________________________________________________________________________________________\ndense_5 (Dense)                 (None, 16)           11280       lambda_22[0][0]                  \n__________________________________________________________________________________________________\nlambda_8 (Lambda)               (None, 1)            0           embedding_6[0][0]                \n__________________________________________________________________________________________________\nlambda_9 (Lambda)               (None, 1)            0           embedding_7[0][0]                \n__________________________________________________________________________________________________\nlambda (Lambda)                 (None, 1)            0           embedding[0][0]                  \n__________________________________________________________________________________________________\nlambda_1 (Lambda)               (None, 1)            0           embedding_1[0][0]                \n__________________________________________________________________________________________________\nlambda_2 (Lambda)               (None, 1)            0           embedding_2[0][0]                \n__________________________________________________________________________________________________\nlambda_3 (Lambda)               (None, 1)            0           embedding_3[0][0]                \n__________________________________________________________________________________________________\nlambda_4 (Lambda)               (None, 1)            0           embedding_4[0][0]                \n__________________________________________________________________________________________________\nlambda_5 (Lambda)               (None, 1)            0           embedding_5[0][0]                \n__________________________________________________________________________________________________\ntf_op_layer_Mul (TensorFlowOpLa [(None, 3520)]       0           lambda_21[0][0]                  \n__________________________________________________________________________________________________\ntf_op_layer_Cast (TensorFlowOpL [(None, 3520)]       0           tf_op_layer_GreaterEqual[0][0]   \n__________________________________________________________________________________________________\ndense_6 (Dense)                 (None, 32)           544         dense_5[0][0]                    \n__________________________________________________________________________________________________\nlambda_10 (Lambda)              (None, 11)           0           input_4[0][0]                    \n                                                                 input_5[0][0]                    \n                                                                 input_3[0][0]                    \n                                                                 lambda_8[0][0]                   \n                                                                 lambda_9[0][0]                   \n                                                                 lambda[0][0]                     \n                                                                 lambda_1[0][0]                   \n                                                                 lambda_2[0][0]                   \n                                                                 lambda_3[0][0]                   \n                                                                 lambda_4[0][0]                   \n                                                                 lambda_5[0][0]                   \n__________________________________________________________________________________________________\ntf_op_layer_Mul_1 (TensorFlowOp [(None, 3520)]       0           tf_op_layer_Mul[0][0]            \n                                                                 tf_op_layer_Cast[0][0]           \n__________________________________________________________________________________________________\ndense_7 (Dense)                 (None, 16)           528         dense_6[0][0]                    \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 32)           384         lambda_10[0][0]                  \n__________________________________________________________________________________________________\ndense_4 (Dense)                 (None, 64)           225344      tf_op_layer_Mul_1[0][0]          \n__________________________________________________________________________________________________\nlambda_23 (Lambda)              (None, 112)          0           dense_7[0][0]                    \n                                                                 dense[0][0]                      \n                                                                 dense_4[0][0]                    \n__________________________________________________________________________________________________\ndense_8 (Dense)                 (None, 1)            113         lambda_23[0][0]                  \n==================================================================================================\nTotal params: 27,383,227\nTrainable params: 27,383,227\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# 编译模型 设置参数"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodel.compile(loss='binary_crossentropy',\n              optimizer= tf.keras.optimizers.Adam(lr=0.003),\n              metrics=['binary_crossentropy',tf.keras.metrics.AUC()])\n\nplateau = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_auc',\n                            verbose=1,\n                            mode='max',\n                            factor=0.1,\n                            patience=3)\n\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_auc',\n                               verbose=1,\n                               mode='max',\n                               patience=2)\n\n# 保存\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(f'fold.h5',\n                             monitor='val_auc',\n                             verbose=1,\n                             mode='max',\n                             save_best_only=True)\n","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# 训练 验证\nvalid = pd.DataFrame()\n#20 为了训练验证更稳定\nfor i in range(6):\n    \n    # 获取训练标签数据\n    last_records = train.drop_duplicates('user_id', keep='last')\n    \n    # 获取训练标签以前的数据\n    map__last_records__user_row = dict(zip(last_records['user_id'],last_records['row_id']))\n    train['filter_row'] = train['user_id'].map(map__last_records__user_row)\n    train = train[train['row_id']<train['filter_row']]\n\n    # 特征加入训练集\n    valid = valid.append(last_records)\n    print(len(valid))\n\n\nfeatures_columns = ['question_difficulty','user_correctness','content_count',\\\n                    'timestamp','prior_question_elapsed_time',\\\n                    'user_id','content_id',\\\n                    'task_container_id','prior_question_had_explanation',\\\n                    'bundle_id','part'\n#                     ,'tags'\n                   ]\n\nX_valid, y_valid = [np.array(valid[columns].values.tolist()) for columns in features_columns], valid['answered_correctly'].values\ndel valid\nprint(\"del\")\nX_train, y_train = [np.array(train[columns].values.tolist()) for columns in features_columns], train['answered_correctly'].values\ndel train\nprint(\"del\")","execution_count":15,"outputs":[{"output_type":"stream","text":"393656\n787225\n1180734\n1574202\n1967602\n2360984\ndel\ndel\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#开始训练\nmodel.fit(X_train, y_train,\n          epochs=15,\n          batch_size=512 *100* 2,\n          verbose=1,\n          shuffle=True,\n          validation_data=(X_valid, y_valid),\n          callbacks=[plateau, early_stopping, checkpoint])\n\ny_valid_proba = model.predict(X_valid, verbose=0, batch_size=512)\nauc = roc_auc_score(y_valid, y_valid_proba)\nprint(auc)\n","execution_count":16,"outputs":[{"output_type":"stream","text":"Epoch 1/15\n223/223 [==============================] - ETA: 0s - loss: 0.5816 - binary_crossentropy: 0.5816 - auc: 0.7387\nEpoch 00001: val_auc improved from -inf to 0.74218, saving model to fold.h5\n223/223 [==============================] - 168s 752ms/step - loss: 0.5816 - binary_crossentropy: 0.5816 - auc: 0.7387 - val_loss: 0.5961 - val_binary_crossentropy: 0.5961 - val_auc: 0.7422\nEpoch 2/15\n223/223 [==============================] - ETA: 0s - loss: 0.5559 - binary_crossentropy: 0.5559 - auc: 0.7697\nEpoch 00002: val_auc improved from 0.74218 to 0.74655, saving model to fold.h5\n223/223 [==============================] - 167s 751ms/step - loss: 0.5559 - binary_crossentropy: 0.5559 - auc: 0.7697 - val_loss: 0.5946 - val_binary_crossentropy: 0.5946 - val_auc: 0.7466\nEpoch 3/15\n223/223 [==============================] - ETA: 0s - loss: 0.5456 - binary_crossentropy: 0.5456 - auc: 0.7798\nEpoch 00003: val_auc did not improve from 0.74655\n223/223 [==============================] - 166s 743ms/step - loss: 0.5456 - binary_crossentropy: 0.5456 - auc: 0.7798 - val_loss: 0.5947 - val_binary_crossentropy: 0.5947 - val_auc: 0.7457\nEpoch 4/15\n223/223 [==============================] - ETA: 0s - loss: 0.5346 - binary_crossentropy: 0.5346 - auc: 0.7900\nEpoch 00004: val_auc did not improve from 0.74655\n223/223 [==============================] - 167s 750ms/step - loss: 0.5346 - binary_crossentropy: 0.5346 - auc: 0.7900 - val_loss: 0.6008 - val_binary_crossentropy: 0.6008 - val_auc: 0.7420\nEpoch 00004: early stopping\n0.7420142880855104\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=tf.keras.models.load_model('fold.h5')\niter_test = env.iter_test()\nprior_test_df = None\nfor (test_df, sample_prediction_df) in iter_test:\n    #用预测完后的数据，更新训练样本中的用户题目特征\n    if prior_test_df is not None:\n        prior_test_df[\"answered_correctly\"] = eval(test_df['prior_group_answers_correct'].iloc[0])\n        prior_test_df = prior_test_df[prior_test_df[\"answered_correctly\"] != -1].reset_index(drop=True)\n        \n        user_ids = prior_test_df['user_id'].values\n        content_ids = prior_test_df['content_id'].values\n        targets = prior_test_df[\"answered_correctly\"].values\n        \n        for user_id, content_id, answered_correctly in zip(user_ids, content_ids, targets):\n            if user_id in user_agg.index:\n                user_agg.loc[user_id, 'sum'] += answered_correctly\n                user_agg.loc[user_id, 'count'] += 1\n            else:\n                user_agg.loc[user_id] = [answered_correctly, 1]\n            \n            if content_id in content_agg.index:\n                content_agg.loc[content_id, 'sum'] += answered_correctly\n                content_agg.loc[content_id, 'count'] += 1\n            else:\n                content_agg.loc[content_id] = [answered_correctly, 1]\n\n    prior_test_df = test_df.copy()\n    \n    test_df['prior_question_had_explanation'] = test_df['prior_question_had_explanation'].map({'True':1,'False':0}).fillna(-1).astype(np.int8)\n    test_df = pd.merge(\n        left=test_df,\n        right=questions,\n        how='left',\n        left_on='content_id',\n        right_on='question_id'\n        )\n    test_df['user_correctness'] = test_df['user_id'].map(user_agg['sum'] / user_agg['count'])\n    \n    test_df['content_count'] = test_df['content_id'].map(content_agg['count']).fillna(1)\n    test_df['question_difficulty'] = test_df['content_id'].map(content_agg['sum'] / content_agg['count']).fillna(0.7)\n    test_df = test_df.fillna(0)\n    #类别特征转换\n    for columns in ['user_id','content_id',\\\n                'task_container_id','prior_question_had_explanation',\\\n                'bundle_id','part']:\n        test_df[columns] = dict_cat_class[columns].transform(test_df[columns])\n        print(columns)\n\n    #数值特征归一化\n    for columns in ['timestamp','prior_question_elapsed_time','content_count',\\\n                'question_difficulty','user_correctness']:\n \n        test_df[columns] = dict_float_class[columns].transform(test_df[columns])\n        print(columns)\n\n#     test_df['tags'] = dict_cat_seq_class['tags'].transform(test_df['tags'])\n#     print('tags')\n    \n    X_test = [np.array(test_df[columns].values.tolist()) for columns in features_columns]\n    test_df['answered_correctly'] =  model.predict(X_test, verbose=0, batch_size=512)\n    env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])\n","execution_count":17,"outputs":[{"output_type":"stream","text":"user_id\ncontent_id\ntask_container_id\nprior_question_had_explanation\nbundle_id\npart\ntimestamp\nprior_question_elapsed_time\ncontent_count\nquestion_difficulty\nuser_correctness\nuser_id\ncontent_id\ntask_container_id\nprior_question_had_explanation\nbundle_id\npart\ntimestamp\nprior_question_elapsed_time\ncontent_count\nquestion_difficulty\nuser_correctness\nuser_id\ncontent_id\ntask_container_id\nprior_question_had_explanation\nbundle_id\npart\ntimestamp\nprior_question_elapsed_time\ncontent_count\nquestion_difficulty\nuser_correctness\nuser_id\ncontent_id\ntask_container_id\nprior_question_had_explanation\nbundle_id\npart\ntimestamp\nprior_question_elapsed_time\ncontent_count\nquestion_difficulty\nuser_correctness\n","name":"stdout"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}